{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class CNN_QNetwork(tf.keras.Model):\n",
        "    def __init__(self, action_size):\n",
        "        super(CNN_QNetwork, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 4, activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.output_layer = tf.keras.layers.Dense(action_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        x = tf.expand_dims(x, -1)  # shape (batch, 6, 7, 1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "\n",
        "class PERMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.buffer = []\n",
        "        self.priorities = []\n",
        "        self.alpha = 0.6\n",
        "\n",
        "    def add(self, experience, error):\n",
        "        max_priority = max(self.priorities, default=1.0)\n",
        "        self.buffer.append(experience)\n",
        "        self.priorities.append(max_priority)\n",
        "        if len(self.buffer) > self.capacity:\n",
        "            self.buffer.pop(0)\n",
        "            self.priorities.pop(0)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        scaled_priorities = np.array(self.priorities) ** self.alpha\n",
        "        probs = scaled_priorities / np.sum(scaled_priorities)\n",
        "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
        "        samples = [self.buffer[i] for i in indices]\n",
        "        return samples, indices\n",
        "\n",
        "    def update(self, indices, errors):\n",
        "        for i, e in zip(indices, errors):\n",
        "            self.priorities[i] = abs(e) + 1e-6"
      ],
      "metadata": {
        "id": "FfHvHmQwW3HW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}